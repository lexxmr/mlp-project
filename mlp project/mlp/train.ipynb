{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "epoch:1 iter:1\n",
      "Acc:0.7400000095367432\n",
      "epoch:1 iter:2\n",
      "Acc:0.7599999904632568\n",
      "epoch:1 iter:3\n",
      "Acc:0.5400000214576721\n",
      "epoch:1 iter:4\n",
      "Acc:0.47999998927116394\n",
      "epoch:1 iter:5\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:6\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:7\n",
      "Acc:0.47999998927116394\n",
      "epoch:1 iter:8\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:9\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:10\n",
      "Acc:0.5199999809265137\n",
      "epoch:1 iter:11\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:12\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:13\n",
      "Acc:0.46000000834465027\n",
      "epoch:1 iter:14\n",
      "Acc:0.7200000286102295\n",
      "epoch:1 iter:15\n",
      "Acc:0.5\n",
      "epoch:1 iter:16\n",
      "Acc:0.5\n",
      "epoch:1 iter:17\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:18\n",
      "Acc:0.47999998927116394\n",
      "epoch:1 iter:19\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:20\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:21\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:22\n",
      "Acc:0.5400000214576721\n",
      "epoch:1 iter:23\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:24\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:25\n",
      "Acc:0.7200000286102295\n",
      "epoch:1 iter:26\n",
      "Acc:0.5199999809265137\n",
      "epoch:1 iter:27\n",
      "Acc:0.5199999809265137\n",
      "epoch:1 iter:28\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:29\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:30\n",
      "Acc:0.5199999809265137\n",
      "epoch:1 iter:31\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:32\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:33\n",
      "Acc:0.5199999809265137\n",
      "epoch:1 iter:34\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:35\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:36\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:37\n",
      "Acc:0.699999988079071\n",
      "epoch:1 iter:38\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:39\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:40\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:41\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:42\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:43\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:44\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:45\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:46\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:47\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:48\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:49\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:50\n",
      "Acc:0.4000000059604645\n",
      "epoch:1 iter:51\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:52\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:53\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:54\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:55\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:56\n",
      "Acc:0.699999988079071\n",
      "epoch:1 iter:57\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:58\n",
      "Acc:0.5400000214576721\n",
      "epoch:1 iter:59\n",
      "Acc:0.699999988079071\n",
      "epoch:1 iter:60\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:61\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:62\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:63\n",
      "Acc:0.46000000834465027\n",
      "epoch:1 iter:64\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:65\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:66\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:67\n",
      "Acc:0.7200000286102295\n",
      "epoch:1 iter:68\n",
      "Acc:0.699999988079071\n",
      "epoch:1 iter:69\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:70\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:71\n",
      "Acc:0.7400000095367432\n",
      "epoch:1 iter:72\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:73\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:74\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:75\n",
      "Acc:0.3799999952316284\n",
      "epoch:1 iter:76\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:77\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:78\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:79\n",
      "Acc:0.7200000286102295\n",
      "epoch:1 iter:80\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:81\n",
      "Acc:0.7200000286102295\n",
      "epoch:1 iter:82\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:83\n",
      "Acc:0.7200000286102295\n",
      "epoch:1 iter:84\n",
      "Acc:0.7400000095367432\n",
      "epoch:1 iter:85\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:86\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:87\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:88\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:89\n",
      "Acc:0.5400000214576721\n",
      "epoch:1 iter:90\n",
      "Acc:0.5799999833106995\n",
      "epoch:1 iter:91\n",
      "Acc:0.6200000047683716\n",
      "epoch:1 iter:92\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:93\n",
      "Acc:0.5400000214576721\n",
      "epoch:1 iter:94\n",
      "Acc:0.6000000238418579\n",
      "epoch:1 iter:95\n",
      "Acc:0.6800000071525574\n",
      "epoch:1 iter:96\n",
      "Acc:0.5600000023841858\n",
      "epoch:1 iter:97\n",
      "Acc:0.6600000262260437\n",
      "epoch:1 iter:98\n",
      "Acc:0.7400000095367432\n",
      "epoch:1 iter:99\n",
      "Acc:0.6399999856948853\n",
      "epoch:1 iter:100\n",
      "Acc:0.5199999809265137\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (5000, 2) for Tensor 'Placeholder_1:0', which has shape '(50, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e1db622fc0f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Valid Acc:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Valid Loss:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1105\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (5000, 2) for Tensor 'Placeholder_1:0', which has shape '(50, 2)'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import data_providers as data_providers\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "batchSize = 50\n",
    "train_data = data_providers.ACLIMDBDataProvider('train', batch_size=batchSize)\n",
    "valid_data = data_providers.ACLIMDBDataProvider('valid', batch_size=5000)\n",
    "# print(train_data.next())\n",
    "def getTrainBatch():\n",
    "\t# inputs, targets = train_data.next()\n",
    "    return train_data.next()\n",
    "def getValBatch():\n",
    "    return valid_data.next()\n",
    "def processBatch(batch):\n",
    "    maxLength = 0\n",
    "    batchLength = np.zeros([batchSize])\n",
    "    for i in range(batchSize):\n",
    "        batchLength[i] = len(batch[i])\n",
    "        if maxLength < len(batch[i]):\n",
    "            maxLength = len(batch[i])\n",
    "    newBatch = np.zeros((batchSize,maxLength))\n",
    "    for i in range(batchSize):\n",
    "        newBatch[i] = np.pad(batch[i],(0,maxLength-len(batch[i])),'constant')\n",
    "    return newBatch, batchLength\n",
    "            \n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "max_epoch = 20\n",
    "maxSeqLength = 2505\n",
    "numDimensions = 300 #Dimensions for each word vector\n",
    "vocab_size = 93929\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [batchSize,None]) #(b,L)\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses]) #(b,2)\n",
    "bacthLength = tf.placeholder(tf.int32, [batchSize])\n",
    "\n",
    "embedding_table = tf.Variable(tf.random_normal([vocab_size, numDimensions]))\n",
    "\n",
    "data = tf.nn.embedding_lookup(embedding_table, input_data) # data(b,max,d)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "\n",
    "outputs, final_states = tf.nn.dynamic_rnn(lstmCell, data, bacthLength, dtype=tf.float32) #final_states.h (b,lstmUnits)\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.zeros([numClasses]))\n",
    "\n",
    "prediction = tf.matmul(final_states.h, weight) + bias\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = labels, logits = prediction))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merge_summary = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(r\"C:\\Users\\Me\\Downloads\\mlp project\\trainSummary\",sess.graph)\n",
    "    valid_writer = tf.summary.FileWriter(r\"C:\\Users\\Me\\Downloads\\mlp project\\validSummary\",sess.graph)\n",
    "    step = 0\n",
    "    sess.run(init)\n",
    "    while step<max_epoch:\n",
    "        step = step+1\n",
    "        print(\"epoch:{}\".format(step))\n",
    "        train_data.new_epoch()\n",
    "        iterations = 0\n",
    "        while iterations<train_data.num_batches:\n",
    "            iterations = iterations + 1\n",
    "            print(\"epoch:{}\".format(step),end=\" \")\n",
    "            print(\"iter:{}\".format(iterations))\n",
    "            train_batch = getTrainBatch()\n",
    "            batch_data, batch_len = processBatch(train_batch[0])\n",
    "            batch_label = train_batch[1]\n",
    "            dict_feed = {}\n",
    "            dict_feed[input_data] = batch_data\n",
    "            dict_feed[labels] = batch_label\n",
    "            dict_feed[bacthLength] = batch_len\n",
    "            sess.run(optimizer, dict_feed)\n",
    "            print(\"Acc:{}\".format(sess.run(accuracy,dict_feed)))\n",
    "            if iterations % 100 == 0:\n",
    "                train_summary = sess.run(merge_summary,dict_feed)\n",
    "                train_writer.add_summary(train_summary,iterations*step)\n",
    "\n",
    "                valid_data.new_epoch()\n",
    "                valid_batch = getValBatch()\n",
    "                valid_batch_data, valid_batch_len = processBatch(valid_batch[0])\n",
    "                valid_batch_label = valid_batch[1]\n",
    "                valid_dict = {}\n",
    "                valid_dict[input_data] = valid_batch_data\n",
    "                valid_dict[labels] = valid_batch_label\n",
    "                valid_dict[bacthLength] = valid_batch_len\n",
    "        \n",
    "                \n",
    "                print(\"Valid Acc:{}\".format(sess.run(accuracy,valid_dict)))\n",
    "                print(\"Valid Loss:{}\".format(sess.run(loss,valid_dict)))\n",
    "                \n",
    "                valid_summary = sess.run(merge_summary, valid_dict)\n",
    "                valid_writer.add_summary(valid_summary, iterations*step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
