{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'<br \\\\>|\\W',' ',text)\n",
    "    words = text.split()\n",
    "    \n",
    "    return [w.lower() for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter\n",
    "import os  \n",
    "path = r\"C:\\Users\\Me\\Downloads\\mlp project\\aclImdb_v1\\aclImdb\\train\\neg\" #文件夹目录  \n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称  \n",
    "maxlen = 0\n",
    "documents = []\n",
    "rates = []\n",
    "vocab = []\n",
    "for file in files: #遍历文件夹    \n",
    "    f = open(path+\"/\"+file,encoding=\"utf-8\"); #打开文件  \n",
    "    iter_f = iter(f); #创建迭代器  \n",
    "    rates.append(file[-5])\n",
    "#     rates.append(file)\n",
    "    for line in iter_f: #遍历文件，一行行遍历，读取文本\n",
    "        words = preprocess(line)\n",
    "        if len(words) > maxlen:\n",
    "            maxlen = len(words)\n",
    "        for word in words:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "            \n",
    "        documents.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Me\\Downloads\\mlp project\\aclImdb_v1\\aclImdb\\train\\pos\" #文件夹目录  \n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称\n",
    "for file in files: #遍历文件夹    \n",
    "    f = open(path+\"/\"+file,encoding=\"utf-8\"); #打开文件  \n",
    "    iter_f = iter(f); #创建迭代器  \n",
    "    if file[-5] == '0':\n",
    "        rates.append(10)\n",
    "    else:\n",
    "        rates.append(file[-5])\n",
    "#     rates.append(file)\n",
    "    for line in iter_f: #遍历文件，一行行遍历，读取文本  \n",
    "        words = preprocess(line)\n",
    "        if len(words) > maxlen:\n",
    "            maxlen = len(words)        \n",
    "        for word in words:\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "            \n",
    "        documents.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74891\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "with open('vocab.txt','w',encoding=\"utf-8\") as f:\n",
    "    for v in vocab:\n",
    "        f.write(v)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  221   222  2940 20864     5  6526    11     2   515     8   241   374\n",
      "    70  9658  1670    52    31    17   176   375  1556     1   418   317\n",
      "   286   488   327   225    46   988   234   947   332   228     1    31\n",
      "   644   449     1   360   239  9823   116    31  8137    84 20864    35\n",
      "   294   286  3344  1982    66    84   251   230   270   314   871    30\n",
      "   418    40   225   988   234   947    31   294   581    54   547   947\n",
      "   332    16     2   488  7000 49142 27137 27138    31  1503    16   253\n",
      "   856    48    92   732     4  3560   253    35    69    70   569   509\n",
      "  1024  1041    84  1148    41  3568     1     2 10460  8137   114   344\n",
      " 19490   726    63    55  3238   191 20864  2139   279   581   286   489\n",
      "   713    31  1386   942   680     1   209  7444 20864  2016   360   683\n",
      "   332 27138    35  9823   581   286  1997   741 27138    16  2539    63\n",
      "    55    31   245    12    41  4781 13924   281 15205    41  3526   335\n",
      "    34   217   683   225   289   445    63   803    52   836    34    48\n",
      "    26   365   116]\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int = {w: c for c, w in enumerate(vocab)}\n",
    "int_to_vocab = {c: w for c, w in enumerate(vocab)}\n",
    "int_documents = []\n",
    "for document in documents:\n",
    "#     int_document = [vocab_to_int[w] for w in document]\n",
    "    int_document = []\n",
    "    for w in document:\n",
    "        if w in vocab:\n",
    "            int_document.append(vocab_to_int[w])\n",
    "    int_documents.append(np.array(int_document).astype(np.int))\n",
    "print(int_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_documents = np.array(int_documents)\n",
    "rates = np.array(rates).astype(np.int)\n",
    "rates[rates<5] = 0\n",
    "rates[rates>5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inputs = np.append(int_documents[:10000], int_documents[12500:22500])\n",
    "train_targets = np.append(rates[:10000], rates[12500:22500])\n",
    "valid_inputs = np.append(int_documents[10000:12500], int_documents[22500:])\n",
    "valid_targets = np.append(rates[10000:12500], rates[22500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"train\", inputs =train_inputs, targets =train_targets)\n",
    "np.savez(\"valid\", inputs =valid_inputs, targets =valid_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter\n",
    "import os  \n",
    "path = r\"C:\\Users\\Me\\Downloads\\mlp project\\aclImdb_v1\\aclImdb\\test\\neg\" #文件夹目录  \n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称  \n",
    "maxlen = 0\n",
    "documents = []\n",
    "rates = []\n",
    "for file in files: #遍历文件夹    \n",
    "    f = open(path+\"/\"+file,encoding=\"utf-8\"); #打开文件  \n",
    "    iter_f = iter(f); #创建迭代器  \n",
    "    rates.append(file[-5])\n",
    "#     rates.append(file)\n",
    "    for line in iter_f: #遍历文件，一行行遍历，读取文本\n",
    "        words = preprocess(line)\n",
    "        documents.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Me\\Downloads\\mlp project\\aclImdb_v1\\aclImdb\\test\\pos\" #文件夹目录  \n",
    "files= os.listdir(path) #得到文件夹下的所有文件名称\n",
    "for file in files: #遍历文件夹    \n",
    "    f = open(path+\"/\"+file,encoding=\"utf-8\"); #打开文件  \n",
    "    iter_f = iter(f); #创建迭代器  \n",
    "    if file[-5] == '0':\n",
    "        rates.append(10)\n",
    "    else:\n",
    "        rates.append(file[-5])\n",
    "#     rates.append(file)\n",
    "    for line in iter_f: #遍历文件，一行行遍历，读取文本  \n",
    "        words = preprocess(line)\n",
    "        documents.append(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(\"test\", inputs =int_documents, targets =rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.load(\"train.npz\")\n",
    "valid_data = np.load(\"valid.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_data['targets']))\n",
    "print(len(valid_data['inputs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_providers as data_providers\n",
    "batch_size = 50\n",
    "train_data = data_providers.ACLIMDBDataProvider(\"train\",batch_size=batch_size)\n",
    "valid_data = data_providers.ACLIMDBDataProvider(\"valid\",batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Me\\Downloads\\mlp project\\mlp\\vocab.txt\") as file_object:\n",
    "    iter_f = iter(file_object)\n",
    "    vocab = []\n",
    "    for line in iter_f:\n",
    "        vocab.append(line[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int = {w: c for c, w in enumerate(vocab)}\n",
    "int_to_vocab = {c: w for c, w in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "war\n",
      "between\n",
      "the\n",
      "states\n",
      "was\n",
      "perhaps\n",
      "the\n",
      "darkest\n",
      "hour\n",
      "in\n",
      "the\n",
      "history\n",
      "of\n",
      "america\n",
      "a\n",
      "war\n",
      "that\n",
      "pitted\n",
      "brother\n",
      "against\n",
      "brother\n",
      "and\n",
      "family\n",
      "against\n",
      "family\n",
      "and\n",
      "left\n",
      "scars\n",
      "that\n",
      "even\n",
      "today\n",
      "have\n",
      "not\n",
      "yet\n",
      "healed\n",
      "and\n",
      "in\n",
      "all\n",
      "probability\n",
      "never\n",
      "will\n",
      "and\n",
      "as\n",
      "in\n",
      "any\n",
      "story\n",
      "about\n",
      "any\n",
      "war\n",
      "beyond\n",
      "any\n",
      "historical\n",
      "significance\n",
      "it\n",
      "is\n",
      "the\n",
      "personal\n",
      "discord\n",
      "behind\n",
      "the\n",
      "greater\n",
      "conflict\n",
      "that\n",
      "creates\n",
      "the\n",
      "emotional\n",
      "impetus\n",
      "that\n",
      "makes\n",
      "it\n",
      "involving\n",
      "it\n",
      "is\n",
      "the\n",
      "human\n",
      "element\n",
      "that\n",
      "renders\n",
      "the\n",
      "context\n",
      "necessary\n",
      "to\n",
      "give\n",
      "it\n",
      "perspective\n",
      "which\n",
      "is\n",
      "what\n",
      "director\n",
      "ang\n",
      "lee\n",
      "provides\n",
      "in\n",
      "ride\n",
      "with\n",
      "the\n",
      "devil\n",
      "a\n",
      "civil\n",
      "war\n",
      "drama\n",
      "in\n",
      "which\n",
      "he\n",
      "focuses\n",
      "on\n",
      "the\n",
      "personal\n",
      "travails\n",
      "within\n",
      "the\n",
      "broader\n",
      "depiction\n",
      "of\n",
      "the\n",
      "war\n",
      "itself\n",
      "and\n",
      "along\n",
      "the\n",
      "way\n",
      "manages\n",
      "to\n",
      "include\n",
      "an\n",
      "examination\n",
      "of\n",
      "one\n",
      "of\n",
      "the\n",
      "bloodiest\n",
      "chapters\n",
      "of\n",
      "the\n",
      "war\n",
      "the\n",
      "infamous\n",
      "raid\n",
      "on\n",
      "lawrence\n",
      "kansas\n",
      "by\n",
      "quantrill\n",
      "and\n",
      "his\n",
      "raiders\n",
      "which\n",
      "he\n",
      "succeeds\n",
      "in\n",
      "presenting\n",
      "quite\n",
      "objectively\n",
      "from\n",
      "the\n",
      "confederate\n",
      "point\n",
      "of\n",
      "view\n",
      "br\n",
      "br\n",
      "in\n",
      "1863\n",
      "the\n",
      "union\n",
      "influence\n",
      "predominates\n",
      "in\n",
      "the\n",
      "state\n",
      "of\n",
      "kansas\n",
      "and\n",
      "even\n",
      "across\n",
      "the\n",
      "border\n",
      "in\n",
      "neighboring\n",
      "missouri\n",
      "those\n",
      "with\n",
      "confederate\n",
      "loyalties\n",
      "are\n",
      "finding\n",
      "it\n",
      "increasingly\n",
      "difficult\n",
      "to\n",
      "hold\n",
      "out\n",
      "against\n",
      "the\n",
      "encroaching\n",
      "northerners\n",
      "especially\n",
      "without\n",
      "the\n",
      "aid\n",
      "of\n",
      "what\n",
      "could\n",
      "be\n",
      "considered\n",
      "any\n",
      "regular\n",
      "confederate\n",
      "troops\n",
      "and\n",
      "when\n",
      "things\n",
      "begin\n",
      "to\n",
      "really\n",
      "heat\n",
      "up\n",
      "around\n",
      "their\n",
      "own\n",
      "town\n",
      "jack\n",
      "bull\n",
      "chiles\n",
      "skeet\n",
      "ulrich\n",
      "and\n",
      "jake\n",
      "roedel\n",
      "tobey\n",
      "maguire\n",
      "form\n",
      "a\n",
      "band\n",
      "of\n",
      "their\n",
      "own\n",
      "and\n",
      "join\n",
      "in\n",
      "the\n",
      "fray\n",
      "doing\n",
      "damage\n",
      "to\n",
      "the\n",
      "union\n",
      "cause\n",
      "wherever\n",
      "it\n",
      "is\n",
      "practicable\n",
      "jack\n",
      "bull\n",
      "and\n",
      "jake\n",
      "do\n",
      "not\n",
      "like\n",
      "the\n",
      "war\n",
      "and\n",
      "do\n",
      "not\n",
      "like\n",
      "killing\n",
      "but\n",
      "they\n",
      "are\n",
      "standing\n",
      "up\n",
      "for\n",
      "what\n",
      "they\n",
      "believe\n",
      "to\n",
      "be\n",
      "right\n",
      "br\n",
      "br\n",
      "there\n",
      "are\n",
      "others\n",
      "however\n",
      "even\n",
      "among\n",
      "their\n",
      "own\n",
      "men\n",
      "like\n",
      "the\n",
      "young\n",
      "pitt\n",
      "mackeson\n",
      "jonathan\n",
      "rhys\n",
      "meyers\n",
      "who\n",
      "will\n",
      "use\n",
      "the\n",
      "conflict\n",
      "as\n",
      "a\n",
      "vehicle\n",
      "for\n",
      "personal\n",
      "gain\n",
      "and\n",
      "as\n",
      "nothing\n",
      "more\n",
      "than\n",
      "an\n",
      "excuse\n",
      "to\n",
      "express\n",
      "their\n",
      "own\n",
      "violent\n",
      "nature\n",
      "through\n",
      "unnecessary\n",
      "brutality\n",
      "perpetrated\n",
      "in\n",
      "many\n",
      "instances\n",
      "against\n",
      "innocent\n",
      "victims\n",
      "and\n",
      "so\n",
      "for\n",
      "jack\n",
      "bull\n",
      "and\n",
      "jake\n",
      "as\n",
      "well\n",
      "as\n",
      "many\n",
      "just\n",
      "like\n",
      "them\n",
      "it\n",
      "becomes\n",
      "a\n",
      "time\n",
      "in\n",
      "which\n",
      "loyalty\n",
      "and\n",
      "moral\n",
      "judgments\n",
      "will\n",
      "be\n",
      "sorely\n",
      "tested\n",
      "a\n",
      "time\n",
      "during\n",
      "which\n",
      "their\n",
      "souls\n",
      "will\n",
      "be\n",
      "tempered\n",
      "in\n",
      "blood\n",
      "and\n",
      "they\n",
      "will\n",
      "have\n",
      "to\n",
      "ride\n",
      "with\n",
      "the\n",
      "very\n",
      "devil\n",
      "himself\n",
      "against\n",
      "seemingly\n",
      "insurmountable\n",
      "odds\n",
      "br\n",
      "br\n",
      "as\n",
      "with\n",
      "all\n",
      "of\n",
      "his\n",
      "films\n",
      "director\n",
      "ang\n",
      "lee\n",
      "approaches\n",
      "his\n",
      "story\n",
      "through\n",
      "an\n",
      "incisive\n",
      "yet\n",
      "subtle\n",
      "examination\n",
      "of\n",
      "the\n",
      "traditions\n",
      "cultural\n",
      "aspects\n",
      "and\n",
      "moral\n",
      "attitudes\n",
      "of\n",
      "the\n",
      "people\n",
      "and\n",
      "times\n",
      "he\n",
      "is\n",
      "depicting\n",
      "and\n",
      "in\n",
      "so\n",
      "doing\n",
      "lee\n",
      "provides\n",
      "his\n",
      "audience\n",
      "with\n",
      "at\n",
      "least\n",
      "some\n",
      "understanding\n",
      "of\n",
      "his\n",
      "subject\n",
      "that\n",
      "goes\n",
      "beyond\n",
      "the\n",
      "actual\n",
      "story\n",
      "and\n",
      "ultimately\n",
      "offers\n",
      "perhaps\n",
      "a\n",
      "deeper\n",
      "grasp\n",
      "of\n",
      "the\n",
      "motivations\n",
      "that\n",
      "propel\n",
      "his\n",
      "characters\n",
      "and\n",
      "the\n",
      "drama\n",
      "in\n",
      "which\n",
      "they\n",
      "are\n",
      "engaged\n",
      "whether\n",
      "it\n",
      "s\n",
      "the\n",
      "traditions\n",
      "and\n",
      "customs\n",
      "that\n",
      "account\n",
      "for\n",
      "the\n",
      "relationship\n",
      "between\n",
      "a\n",
      "father\n",
      "and\n",
      "his\n",
      "daughters\n",
      "eat\n",
      "drink\n",
      "man\n",
      "woman\n",
      "the\n",
      "effects\n",
      "of\n",
      "class\n",
      "distinction\n",
      "sense\n",
      "and\n",
      "sensibility\n",
      "the\n",
      "honor\n",
      "and\n",
      "code\n",
      "by\n",
      "which\n",
      "a\n",
      "warrior\n",
      "lives\n",
      "and\n",
      "dies\n",
      "crouching\n",
      "tiger\n",
      "hidden\n",
      "dragon\n",
      "or\n",
      "the\n",
      "moral\n",
      "ambiguities\n",
      "fostered\n",
      "by\n",
      "a\n",
      "lack\n",
      "of\n",
      "all\n",
      "of\n",
      "the\n",
      "above\n",
      "the\n",
      "ice\n",
      "storm\n",
      "lee\n",
      "infuses\n",
      "his\n",
      "films\n",
      "with\n",
      "insights\n",
      "into\n",
      "the\n",
      "human\n",
      "condition\n",
      "that\n",
      "take\n",
      "them\n",
      "to\n",
      "a\n",
      "higher\n",
      "level\n",
      "this\n",
      "film\n",
      "is\n",
      "no\n",
      "exception\n",
      "and\n",
      "as\n",
      "he\n",
      "does\n",
      "with\n",
      "all\n",
      "his\n",
      "films\n",
      "lee\n",
      "presents\n",
      "his\n",
      "story\n",
      "with\n",
      "the\n",
      "aid\n",
      "of\n",
      "breathtaking\n",
      "cinematography\n",
      "in\n",
      "this\n",
      "film\n",
      "by\n",
      "frederick\n",
      "elmes\n",
      "who\n",
      "also\n",
      "did\n",
      "the\n",
      "ice\n",
      "storm\n",
      "brilliantly\n",
      "which\n",
      "under\n",
      "his\n",
      "guidance\n",
      "is\n",
      "nothing\n",
      "less\n",
      "than\n",
      "visual\n",
      "poetry\n",
      "it\n",
      "s\n",
      "that\n",
      "special\n",
      "lee\n",
      "touch\n",
      "and\n",
      "it\n",
      "adds\n",
      "a\n",
      "wistful\n",
      "reflective\n",
      "sense\n",
      "to\n",
      "whatever\n",
      "story\n",
      "he\n",
      "is\n",
      "telling\n",
      "which\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "elements\n",
      "that\n",
      "make\n",
      "his\n",
      "films\n",
      "so\n",
      "memorable\n",
      "br\n",
      "br\n",
      "as\n",
      "jake\n",
      "tobey\n",
      "maguire\n",
      "initially\n",
      "brings\n",
      "a\n",
      "sense\n",
      "of\n",
      "youthful\n",
      "innocence\n",
      "to\n",
      "the\n",
      "film\n",
      "that\n",
      "contrasts\n",
      "so\n",
      "effectively\n",
      "with\n",
      "the\n",
      "maturity\n",
      "he\n",
      "conveys\n",
      "later\n",
      "on\n",
      "as\n",
      "the\n",
      "story\n",
      "develops\n",
      "and\n",
      "his\n",
      "character\n",
      "along\n",
      "with\n",
      "it\n",
      "most\n",
      "importantly\n",
      "maguire\n",
      "convincingly\n",
      "and\n",
      "believably\n",
      "responds\n",
      "to\n",
      "the\n",
      "events\n",
      "that\n",
      "unfold\n",
      "around\n",
      "him\n",
      "which\n",
      "adds\n",
      "to\n",
      "the\n",
      "credibility\n",
      "of\n",
      "the\n",
      "overall\n",
      "film\n",
      "and\n",
      "underscores\n",
      "the\n",
      "realism\n",
      "of\n",
      "the\n",
      "presentation\n",
      "his\n",
      "stoic\n",
      "acceptance\n",
      "of\n",
      "death\n",
      "and\n",
      "the\n",
      "news\n",
      "of\n",
      "those\n",
      "murdered\n",
      "in\n",
      "the\n",
      "various\n",
      "skirmishes\n",
      "and\n",
      "battles\n",
      "the\n",
      "moral\n",
      "propriety\n",
      "to\n",
      "which\n",
      "those\n",
      "he\n",
      "encounters\n",
      "adhere\n",
      "even\n",
      "in\n",
      "such\n",
      "troubled\n",
      "times\n",
      "the\n",
      "betrayal\n",
      "which\n",
      "because\n",
      "of\n",
      "the\n",
      "nature\n",
      "of\n",
      "the\n",
      "conflict\n",
      "is\n",
      "almost\n",
      "commonplace\n",
      "and\n",
      "the\n",
      "loyalty\n",
      "and\n",
      "beliefs\n",
      "to\n",
      "which\n",
      "he\n",
      "and\n",
      "his\n",
      "companions\n",
      "cling\n",
      "adamantly\n",
      "it\n",
      "is\n",
      "all\n",
      "of\n",
      "this\n",
      "that\n",
      "maguire\n",
      "achieves\n",
      "through\n",
      "his\n",
      "performance\n",
      "and\n",
      "it\n",
      "is\n",
      "no\n",
      "small\n",
      "accomplishment\n",
      "it\n",
      "is\n",
      "however\n",
      "the\n",
      "kind\n",
      "of\n",
      "studied\n",
      "understated\n",
      "performance\n",
      "that\n",
      "is\n",
      "often\n",
      "taken\n",
      "for\n",
      "granted\n",
      "which\n",
      "is\n",
      "unfortunate\n",
      "work\n",
      "like\n",
      "this\n",
      "is\n",
      "worthy\n",
      "of\n",
      "acclaim\n",
      "and\n",
      "should\n",
      "be\n",
      "recognized\n",
      "br\n",
      "br\n",
      "skeet\n",
      "ulrich\n",
      "is\n",
      "effective\n",
      "as\n",
      "well\n",
      "as\n",
      "jack\n",
      "bull\n",
      "and\n",
      "jewel\n",
      "in\n",
      "her\n",
      "motion\n",
      "picture\n",
      "debut\n",
      "turns\n",
      "in\n",
      "an\n",
      "engaging\n",
      "performance\n",
      "as\n",
      "sue\n",
      "lee\n",
      "shelley\n",
      "it\n",
      "is\n",
      "jeffrey\n",
      "wright\n",
      "however\n",
      "who\n",
      "stands\n",
      "out\n",
      "in\n",
      "a\n",
      "notable\n",
      "supporting\n",
      "role\n",
      "as\n",
      "daniel\n",
      "holt\n",
      "as\n",
      "well\n",
      "as\n",
      "jonathan\n",
      "rhys\n",
      "meyers\n",
      "who\n",
      "brings\n",
      "a\n",
      "chilling\n",
      "christopher\n",
      "walken\n",
      "like\n",
      "menace\n",
      "to\n",
      "his\n",
      "role\n",
      "of\n",
      "pitt\n",
      "also\n",
      "in\n",
      "what\n",
      "amounts\n",
      "to\n",
      "a\n",
      "cameo\n",
      "role\n",
      "one\n",
      "scene\n",
      "mark\n",
      "ruffalo\n",
      "leaves\n",
      "an\n",
      "indelible\n",
      "impression\n",
      "with\n",
      "very\n",
      "little\n",
      "screen\n",
      "time\n",
      "br\n",
      "br\n",
      "the\n",
      "supporting\n",
      "cast\n",
      "includes\n",
      "james\n",
      "caviezel\n",
      "black\n",
      "john\n",
      "simon\n",
      "baker\n",
      "george\n",
      "clyde\n",
      "tom\n",
      "guiry\n",
      "riley\n",
      "tom\n",
      "wilkinson\n",
      "orton\n",
      "brown\n",
      "john\n",
      "ales\n",
      "quantrill\n",
      "john\n",
      "judd\n",
      "otto\n",
      "roedel\n",
      "and\n",
      "kathleen\n",
      "warfel\n",
      "mrs\n",
      "chiles\n",
      "the\n",
      "civil\n",
      "war\n",
      "will\n",
      "forever\n",
      "be\n",
      "an\n",
      "open\n",
      "wound\n",
      "upon\n",
      "the\n",
      "nation\n",
      "but\n",
      "hopefully\n",
      "as\n",
      "time\n",
      "goes\n",
      "on\n",
      "it\n",
      "will\n",
      "be\n",
      "through\n",
      "the\n",
      "objective\n",
      "contemplations\n",
      "of\n",
      "filmmakers\n",
      "like\n",
      "ang\n",
      "lee\n",
      "and\n",
      "films\n",
      "like\n",
      "ride\n",
      "with\n",
      "the\n",
      "devil\n",
      "that\n",
      "will\n",
      "ultimately\n",
      "help\n",
      "to\n",
      "close\n",
      "the\n",
      "schism\n",
      "and\n",
      "promote\n",
      "healing\n",
      "in\n",
      "light\n",
      "of\n",
      "more\n",
      "recent\n",
      "events\n",
      "it\n",
      "is\n",
      "something\n",
      "that\n",
      "is\n",
      "sorely\n",
      "needed\n",
      "worldwide\n",
      "film\n",
      "is\n",
      "a\n",
      "powerful\n",
      "medium\n",
      "it\n",
      "can\n",
      "be\n",
      "educational\n",
      "as\n",
      "well\n",
      "as\n",
      "entertaining\n",
      "and\n",
      "perhaps\n",
      "in\n",
      "the\n",
      "future\n",
      "more\n",
      "filmmakers\n",
      "like\n",
      "ang\n",
      "lee\n",
      "will\n",
      "embrace\n",
      "and\n",
      "promote\n",
      "a\n",
      "sense\n",
      "of\n",
      "unity\n",
      "through\n",
      "the\n",
      "sensitive\n",
      "depiction\n",
      "of\n",
      "the\n",
      "events\n",
      "and\n",
      "attitudes\n",
      "that\n",
      "make\n",
      "us\n",
      "what\n",
      "we\n",
      "are\n",
      "8\n",
      "10\n",
      "br\n",
      "br\n",
      "br\n",
      "br\n",
      "br\n",
      "br\n"
     ]
    }
   ],
   "source": [
    "for c in train_data.next()[0][0]:\n",
    "    print(int_to_vocab[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
